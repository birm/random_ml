{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Twitter Political Classification"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The goal of this project is to determine US Political Party Affiliation by Twitter Usage"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Getting Data"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "INFO: {'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201'}\n"
    }
   ],
   "source": "import twitterscraper"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"Democrats\" selected are Bernie Sanders, Elizabeth Warren, and Joe Biden. These will be encoded as party=0"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": "democratHandles = [\"berniesanders\",\"ewarren\",\"JoeBiden\"]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\"Republicans\" selected are Mitch McConnel, Ted Cruz, and Devin Nunes"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": "republicanHandles = [\"tedcruz\", \"senatemajldr\", \"DevinNunes\"]"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "INFO: Scraping tweets from https://twitter.com/berniesanders\nINFO: Using proxy 123.209.96.233:8080\nINFO: Scraping tweets from https://twitter.com/i/profiles/show/berniesanders/timeline/tweets?include_available_features=1&include_entities=1&max_position=1220360497926692864&reset_error_state=false\nINFO: Using proxy 181.196.242.126:53281\nERROR: An unknown error occurred! Returning tweets gathered so far.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 255, in query_tweets_from_user\n    new_tweets, pos = query_single_page(user, lang='', pos=pos, from_user=True)\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 139, in query_single_page\n    except json.decoder.JSONDecodeError as e:\nAttributeError: 'module' object has no attribute 'JSONDecodeError'\nINFO: Got 13 tweets from username berniesanders.\nINFO: Scraping tweets from https://twitter.com/ewarren\nINFO: Using proxy 212.73.69.6:59763\nINFO: Scraping tweets from https://twitter.com/i/profiles/show/ewarren/timeline/tweets?include_available_features=1&include_entities=1&max_position=1220381560484114434&reset_error_state=false\nINFO: Using proxy 118.173.205.84:8080\nERROR: An unknown error occurred! Returning tweets gathered so far.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 255, in query_tweets_from_user\n    new_tweets, pos = query_single_page(user, lang='', pos=pos, from_user=True)\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 139, in query_single_page\n    except json.decoder.JSONDecodeError as e:\nAttributeError: 'module' object has no attribute 'JSONDecodeError'\nINFO: Got 17 tweets from username ewarren.\nINFO: Scraping tweets from https://twitter.com/JoeBiden\nINFO: Using proxy 103.225.206.22:31777\nINFO: Scraping tweets from https://twitter.com/i/profiles/show/JoeBiden/timeline/tweets?include_available_features=1&include_entities=1&max_position=1219798086127509505&reset_error_state=false\nINFO: Using proxy 18.138.58.188:8118\nERROR: An unknown error occurred! Returning tweets gathered so far.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 255, in query_tweets_from_user\n    new_tweets, pos = query_single_page(user, lang='', pos=pos, from_user=True)\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 139, in query_single_page\n    except json.decoder.JSONDecodeError as e:\nAttributeError: 'module' object has no attribute 'JSONDecodeError'\nINFO: Got 15 tweets from username JoeBiden.\n"
    }
   ],
   "source": "demTweets = [twitterscraper.query_tweets_from_user(x, 500) for x in democratHandles]"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": "demTweets = [x for s in demTweets for x in s]"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": "demTweets = [{\"text\":x.text, \"party\":0} for x in demTweets]"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'party': 0,\n 'text': u'Congratulations to labor activists and working class Minneapolitans on another hard fought victory to raise the minimum wage to $15 an hour. Now we must follow their lead and ensure a livable wage in all 50 states.http://www.startribune.com/minnesota-supreme-court-says-minneapolis-15-minimum-wage-can-stand/567197132/?om_rid=57792626121&om_mid=627378633\\xa0\\u2026'}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "demTweets[0]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<span style=\"color:red\">TODO -- This semeed to fail to get as many tweets as expected. Something wrong with scraper?</span>"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "INFO: Scraping tweets from https://twitter.com/tedcruz\nINFO: Using proxy 159.65.13.147:8080\nINFO: Scraping tweets from https://twitter.com/i/profiles/show/tedcruz/timeline/tweets?include_available_features=1&include_entities=1&max_position=1220442990931369984&reset_error_state=false\nINFO: Using proxy 193.200.151.158:57532\nERROR: An unknown error occurred! Returning tweets gathered so far.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 255, in query_tweets_from_user\n    new_tweets, pos = query_single_page(user, lang='', pos=pos, from_user=True)\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 139, in query_single_page\n    except json.decoder.JSONDecodeError as e:\nAttributeError: 'module' object has no attribute 'JSONDecodeError'\nINFO: Got 17 tweets from username tedcruz.\nINFO: Scraping tweets from https://twitter.com/senatemajldr\nINFO: Using proxy 193.193.240.37:45944\nINFO: Scraping tweets from https://twitter.com/i/profiles/show/senatemajldr/timeline/tweets?include_available_features=1&include_entities=1&max_position=1216893148686843904&reset_error_state=false\nINFO: Using proxy 110.164.91.50:51065\nERROR: An unknown error occurred! Returning tweets gathered so far.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 255, in query_tweets_from_user\n    new_tweets, pos = query_single_page(user, lang='', pos=pos, from_user=True)\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 139, in query_single_page\n    except json.decoder.JSONDecodeError as e:\nAttributeError: 'module' object has no attribute 'JSONDecodeError'\nINFO: Got 6 tweets from username senatemajldr.\nINFO: Scraping tweets from https://twitter.com/DevinNunes\nINFO: Using proxy 191.7.193.50:55590\nINFO: Scraping tweets from https://twitter.com/i/profiles/show/DevinNunes/timeline/tweets?include_available_features=1&include_entities=1&max_position=1218530521438777345&reset_error_state=false\nINFO: Using proxy 67.60.137.219:35979\nERROR: An unknown error occurred! Returning tweets gathered so far.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 255, in query_tweets_from_user\n    new_tweets, pos = query_single_page(user, lang='', pos=pos, from_user=True)\n  File \"/usr/local/lib/python2.7/dist-packages/twitterscraper/query.py\", line 139, in query_single_page\n    except json.decoder.JSONDecodeError as e:\nAttributeError: 'module' object has no attribute 'JSONDecodeError'\nINFO: Got 20 tweets from username DevinNunes.\n"
    }
   ],
   "source": "repTweets = [twitterscraper.query_tweets_from_user(x, 500) for x in republicanHandles]"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": "repTweets = [x for s in repTweets for x in s]"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": "repTweets = [{\"text\":x.text, \"party\":1} for x in repTweets]"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'party': 1,\n 'text': u'A new, right-off-the-senate-floor podcast on the #ImpeachmentTrial was launched by Sen. @tedcruz and commentator @michaeljknowles.https://thetexan.news/sen-ted-cruz-starts-impeachment-podcast-with-the-daily-wires-michael-knowles/\\xa0\\u2026'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "repTweets[0]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Ok, we have some labeled tweets now. Let's put them together."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": "labeledTweets = repTweets + demTweets"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "How many do we have?"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "88"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "len(labeledTweets)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "88 (as of writing this). 88?! That's not very good. Despite better judgement, I'll try this anyway."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## The Model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Especially considring how bad this data is, let's be lazy and use keras"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": "import tensorflow as tf\nimport numpy as np"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string], '')\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We don't have enough for good validation now, and we have very little data, so I'll just do 90% train 10% test"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": "import random, math"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": "random.shuffle(labeledTweets)"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": "splitNum = int(math.floor(len(labeledTweets)*0.1))"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": "testData = labeledTweets[:splitNum]"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": "trainData = labeledTweets[splitNum:]"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training Examples: 80 Test Examples: 8\n"
    }
   ],
   "source": "print(\"Training Examples: \" + str(len(trainData)) + \" Test Examples: \" + str(len(testData)))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "let's make this a dataset, then an input"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000)"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": "tokenizer.fit_on_texts([x['text'] for x in trainData])"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": "tokenizer.fit_on_texts([x['text'] for x in testData])"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": "X_train = tokenizer.texts_to_sequences([x['text'] for x in trainData])"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": "X_test = tokenizer.texts_to_sequences([x['text'] for x in testData])"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding=\"post\", maxlen=20)"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding=\"post\", maxlen=20)"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": "model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(5000, 32),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": "model.compile(loss='binary_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['binary_accuracy'])\n"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 32)          160000    \n_________________________________________________________________\nbidirectional (Bidirectional (None, 32)                6272      \n_________________________________________________________________\ndense (Dense)                (None, 16)                528       \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 166,817\nTrainable params: 166,817\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": "print(model.summary())"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": "Y_train = [float(x['party']) for x in trainData]"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": "Y_test = [float(x['party']) for y in testData]"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 80 samples\nEpoch 1/100\n80/80 [==============================] - 3s 34ms/sample - loss: 0.6927 - binary_accuracy: 0.5875\nEpoch 2/100\n80/80 [==============================] - 0s 674us/sample - loss: 0.6921 - binary_accuracy: 0.6125\nEpoch 3/100\n80/80 [==============================] - 0s 612us/sample - loss: 0.6916 - binary_accuracy: 0.6250\nEpoch 4/100\n80/80 [==============================] - 0s 601us/sample - loss: 0.6912 - binary_accuracy: 0.6375\nEpoch 5/100\n80/80 [==============================] - 0s 629us/sample - loss: 0.6907 - binary_accuracy: 0.6375\nEpoch 6/100\n80/80 [==============================] - 0s 596us/sample - loss: 0.6903 - binary_accuracy: 0.6375\nEpoch 7/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6899 - binary_accuracy: 0.6500\nEpoch 8/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6894 - binary_accuracy: 0.6750\nEpoch 9/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6890 - binary_accuracy: 0.7000\nEpoch 10/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6885 - binary_accuracy: 0.7125\nEpoch 11/100\n80/80 [==============================] - 0s 638us/sample - loss: 0.6881 - binary_accuracy: 0.7125\nEpoch 12/100\n80/80 [==============================] - 0s 997us/sample - loss: 0.6876 - binary_accuracy: 0.7125\nEpoch 13/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6872 - binary_accuracy: 0.7375\nEpoch 14/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6867 - binary_accuracy: 0.7250\nEpoch 15/100\n80/80 [==============================] - 0s 887us/sample - loss: 0.6862 - binary_accuracy: 0.7625\nEpoch 16/100\n80/80 [==============================] - 0s 717us/sample - loss: 0.6857 - binary_accuracy: 0.7875\nEpoch 17/100\n80/80 [==============================] - 0s 804us/sample - loss: 0.6852 - binary_accuracy: 0.8125\nEpoch 18/100\n80/80 [==============================] - 0s 671us/sample - loss: 0.6846 - binary_accuracy: 0.8375\nEpoch 19/100\n80/80 [==============================] - 0s 837us/sample - loss: 0.6841 - binary_accuracy: 0.8375\nEpoch 20/100\n80/80 [==============================] - 0s 872us/sample - loss: 0.6835 - binary_accuracy: 0.8375\nEpoch 21/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6830 - binary_accuracy: 0.8375\nEpoch 22/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6823 - binary_accuracy: 0.8500\nEpoch 23/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6817 - binary_accuracy: 0.8625\nEpoch 24/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6811 - binary_accuracy: 0.8750\nEpoch 25/100\n80/80 [==============================] - 0s 844us/sample - loss: 0.6804 - binary_accuracy: 0.8750\nEpoch 26/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6797 - binary_accuracy: 0.8750\nEpoch 27/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6790 - binary_accuracy: 0.8750\nEpoch 28/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6783 - binary_accuracy: 0.9000\nEpoch 29/100\n80/80 [==============================] - 0s 907us/sample - loss: 0.6775 - binary_accuracy: 0.9125\nEpoch 30/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6767 - binary_accuracy: 0.9125\nEpoch 31/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6759 - binary_accuracy: 0.9125\nEpoch 32/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6750 - binary_accuracy: 0.9250\nEpoch 33/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6742 - binary_accuracy: 0.9250\nEpoch 34/100\n80/80 [==============================] - ETA: 0s - loss: 0.6742 - binary_accuracy: 0.937 - 0s 1ms/sample - loss: 0.6732 - binary_accuracy: 0.9375\nEpoch 35/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6724 - binary_accuracy: 0.9375\nEpoch 36/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6713 - binary_accuracy: 0.9375\nEpoch 37/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6703 - binary_accuracy: 0.9375\nEpoch 38/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6692 - binary_accuracy: 0.9375\nEpoch 39/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6681 - binary_accuracy: 0.9375\nEpoch 40/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6668 - binary_accuracy: 0.9375\nEpoch 41/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6656 - binary_accuracy: 0.9375\nEpoch 42/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6643 - binary_accuracy: 0.9375\nEpoch 43/100\n80/80 [==============================] - 0s 2ms/sample - loss: 0.6629 - binary_accuracy: 0.9375\nEpoch 44/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6616 - binary_accuracy: 0.9375\nEpoch 45/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6601 - binary_accuracy: 0.9375\nEpoch 46/100\n80/80 [==============================] - 0s 3ms/sample - loss: 0.6586 - binary_accuracy: 0.9375\nEpoch 47/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6570 - binary_accuracy: 0.9375\nEpoch 48/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6554 - binary_accuracy: 0.9250\nEpoch 49/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6537 - binary_accuracy: 0.9250\nEpoch 50/100\n80/80 [==============================] - 0s 940us/sample - loss: 0.6520 - binary_accuracy: 0.9250\nEpoch 51/100\n80/80 [==============================] - 0s 924us/sample - loss: 0.6502 - binary_accuracy: 0.9250\nEpoch 52/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6483 - binary_accuracy: 0.9250\nEpoch 53/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6464 - binary_accuracy: 0.9250\nEpoch 54/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6445 - binary_accuracy: 0.9375\nEpoch 55/100\n80/80 [==============================] - 0s 1ms/sample - loss: 0.6424 - binary_accuracy: 0.9375\nEpoch 56/100\n80/80 [==============================] - 0s 790us/sample - loss: 0.6402 - binary_accuracy: 0.9375\nEpoch 57/100\n80/80 [==============================] - 0s 846us/sample - loss: 0.6380 - binary_accuracy: 0.9375\nEpoch 58/100\n80/80 [==============================] - 0s 964us/sample - loss: 0.6358 - binary_accuracy: 0.9375\nEpoch 59/100\n80/80 [==============================] - 0s 752us/sample - loss: 0.6333 - binary_accuracy: 0.9375\nEpoch 60/100\n80/80 [==============================] - 0s 756us/sample - loss: 0.6309 - binary_accuracy: 0.9375\nEpoch 61/100\n80/80 [==============================] - 0s 919us/sample - loss: 0.6283 - binary_accuracy: 0.9375\nEpoch 62/100\n80/80 [==============================] - 0s 844us/sample - loss: 0.6256 - binary_accuracy: 0.9375\nEpoch 63/100\n80/80 [==============================] - 0s 880us/sample - loss: 0.6228 - binary_accuracy: 0.9375\nEpoch 64/100\n80/80 [==============================] - 0s 474us/sample - loss: 0.6199 - binary_accuracy: 0.9375\nEpoch 65/100\n80/80 [==============================] - 0s 895us/sample - loss: 0.6169 - binary_accuracy: 0.9375\nEpoch 66/100\n80/80 [==============================] - 0s 927us/sample - loss: 0.6137 - binary_accuracy: 0.9500\nEpoch 67/100\n80/80 [==============================] - 0s 943us/sample - loss: 0.6104 - binary_accuracy: 0.9500\nEpoch 68/100\n80/80 [==============================] - 0s 792us/sample - loss: 0.6070 - binary_accuracy: 0.9500\nEpoch 69/100\n80/80 [==============================] - 0s 894us/sample - loss: 0.6034 - binary_accuracy: 0.9500\nEpoch 70/100\n80/80 [==============================] - 0s 689us/sample - loss: 0.5998 - binary_accuracy: 0.9500\nEpoch 71/100\n80/80 [==============================] - 0s 683us/sample - loss: 0.5959 - binary_accuracy: 0.9500\nEpoch 72/100\n80/80 [==============================] - 0s 726us/sample - loss: 0.5918 - binary_accuracy: 0.9500\nEpoch 73/100\n80/80 [==============================] - 0s 623us/sample - loss: 0.5876 - binary_accuracy: 0.9500\nEpoch 74/100\n80/80 [==============================] - 0s 626us/sample - loss: 0.5831 - binary_accuracy: 0.9500\nEpoch 75/100\n80/80 [==============================] - 0s 762us/sample - loss: 0.5784 - binary_accuracy: 0.9625\nEpoch 76/100\n80/80 [==============================] - 0s 552us/sample - loss: 0.5736 - binary_accuracy: 0.9625\nEpoch 77/100\n80/80 [==============================] - 0s 604us/sample - loss: 0.5687 - binary_accuracy: 0.9625\nEpoch 78/100\n80/80 [==============================] - 0s 516us/sample - loss: 0.5636 - binary_accuracy: 0.9625\nEpoch 79/100\n80/80 [==============================] - 0s 521us/sample - loss: 0.5584 - binary_accuracy: 0.9625\nEpoch 80/100\n80/80 [==============================] - 0s 463us/sample - loss: 0.5525 - binary_accuracy: 0.9625\nEpoch 81/100\n80/80 [==============================] - 0s 483us/sample - loss: 0.5467 - binary_accuracy: 0.9625\nEpoch 82/100\n80/80 [==============================] - 0s 495us/sample - loss: 0.5409 - binary_accuracy: 0.9750\nEpoch 83/100\n80/80 [==============================] - 0s 617us/sample - loss: 0.5346 - binary_accuracy: 0.9750\nEpoch 84/100\n80/80 [==============================] - 0s 485us/sample - loss: 0.5283 - binary_accuracy: 0.9750\nEpoch 85/100\n80/80 [==============================] - 0s 550us/sample - loss: 0.5216 - binary_accuracy: 0.9750\nEpoch 86/100\n80/80 [==============================] - 0s 493us/sample - loss: 0.5150 - binary_accuracy: 0.9750\nEpoch 87/100\n80/80 [==============================] - 0s 513us/sample - loss: 0.5079 - binary_accuracy: 0.9750\nEpoch 88/100\n80/80 [==============================] - 0s 585us/sample - loss: 0.5006 - binary_accuracy: 0.9625\nEpoch 89/100\n80/80 [==============================] - 0s 521us/sample - loss: 0.4933 - binary_accuracy: 0.9625\nEpoch 90/100\n80/80 [==============================] - 0s 480us/sample - loss: 0.4855 - binary_accuracy: 0.9625\nEpoch 91/100\n80/80 [==============================] - 0s 544us/sample - loss: 0.4779 - binary_accuracy: 0.9625\nEpoch 92/100\n80/80 [==============================] - 0s 568us/sample - loss: 0.4700 - binary_accuracy: 0.9625\nEpoch 93/100\n80/80 [==============================] - 0s 540us/sample - loss: 0.4615 - binary_accuracy: 0.9625\nEpoch 94/100\n80/80 [==============================] - 0s 589us/sample - loss: 0.4533 - binary_accuracy: 0.9625\nEpoch 95/100\n80/80 [==============================] - 0s 696us/sample - loss: 0.4448 - binary_accuracy: 0.9625\nEpoch 96/100\n80/80 [==============================] - 0s 513us/sample - loss: 0.4366 - binary_accuracy: 0.9750\nEpoch 97/100\n80/80 [==============================] - 0s 559us/sample - loss: 0.4277 - binary_accuracy: 0.9750\nEpoch 98/100\n80/80 [==============================] - 0s 608us/sample - loss: 0.4193 - binary_accuracy: 0.9750\nEpoch 99/100\n80/80 [==============================] - 0s 565us/sample - loss: 0.4105 - binary_accuracy: 0.9750\nEpoch 100/100\n80/80 [==============================] - 0s 658us/sample - loss: 0.4020 - binary_accuracy: 0.9750\n"
    }
   ],
   "source": "h = model.fit(x=X_train, y=np.asarray(Y_train), epochs=100)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This is almost certainly overfit, but time for...."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Evaluating"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": "predictions = model.predict(x=X_test)"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "8/8 [==============================] - 1s 68ms/sample - loss: 0.4438 - binary_accuracy: 0.8750\n"
    }
   ],
   "source": "score = model.evaluate(X_test, np.asarray(Y_test))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Well, 88% isn't bad. Maybe. Well, that's all I can do here for now. I may revisit this with better data.\n-RB"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
